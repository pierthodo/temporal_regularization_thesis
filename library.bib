@book{box94,
author={Box, George and Jenkins, Gwilym M. and Reinsel, Gregory C.},
title={Time Series Analysis: Forecasting and Control (3rd ed.)},
year={1994},
publisher={Prentice-Hall}
}

@inproceedings{dhingra17,
author={Dhingra, Bhuwan and Li, Lihong and Li, Xiujun and Gao, Jianfeng and Chen, Yun-Nung and Ahmed, Faisal and Deng, Li},
title={Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access},
booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
  volume={1},
  pages={484--495},
  year={2017}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}


@inproceedings{prasad17,
title={A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in Intensive Care Units},
author={Prasad, N. and Cheng, L.F. and Chivers, C. and Draugelis, M. and Engelhardt, B.E.},
booktitle={UAI},
year={2017}
}


@article{shortreed11,
title={Informing sequential clinical decision-making through
reinforcement learning: an empirical study},
author={Shortreed, S. and Laber, E. and Lizotte, D. and Stroup, S. and Pineau, J. and Murphy, S.A.},
journal={Machine Learning},
year={2011}
}

@article{koedinger18,
author={Koedinger, K.R. and Brunskill, E. and Baker, R.S.J.d. and McLaughlin, E.A.},
title={New Potentials for Data-Driven Intelligent Tutoring System Development and Optimization},
journal={AAAI magazine},
year={2018}
}


@article{silver16,
author={Silver, D. and Huang, A. and Maddison, C.J. and Guez, A. and Sifre, L. and Driessche, G. and Schrittwieser, J. and Antonoglou, I. and Panneershelvam, V. and Lanctot, M. and Dieleman, S. and Grewe, D. and Nham, J. and Kalchbrenner, N. and Sutskever, I. and Lillicrap, T. and Leach, M. and Kavukcuoglu, K. and Graepel, T. and Hassabis, D.},
title={Mastering the game of Go with deep neural networks and tree search},
journal={Nature},
year={2016}
}



@article{fill1991eigenvalue,
  title={Eigenvalue Bounds on Convergence to Stationarity for Nonreversible Markov Chains, with an Application to the Exclusion Process},
  author={Fill, James Allen and others},
  journal={The Annals of Applied Probability},
  volume={1},
  number={1},
  pages={62--87},
  year={1991},
  publisher={Institute of Mathematical Statistics}
}

@article{sobol1993simple,
  title={A Simple Method to Adjust Exponential Smoothing Forecasts for Trend and Seasonality},
  author={Sobol, Marion G and Collins, Jim},
  year={1993}
}
@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  year={2002},
  volume={49},
  number={2-3},
  pages={209--232},
  publisher={Springer}
}

@article{chung2012chernoff,
  title={Chernoff-Hoeffding bounds for Markov chains: Generalized and simplified},
  author={Chung, Kai-Min and Lam, Henry and Liu, Zhenming and Mitzenmacher, Michael},
  journal={arXiv preprint arXiv:1201.0559},
  year={2012}
}
@inproceedings{seijen2014true,
  title={True online TD (lambda)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}
@inproceedings{xu2017natural,
  title={Natural Value Approximators: Learning when to Trust Past Estimates},
  author={Xu, Zhongwen and Modayil, Joseph and van Hasselt, Hado P and Barreto, Andre and Silver, David and Schaul, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2117--2125},
  year={2017}
}
@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}
@article{gardner2006exponential,
  title={Exponential smoothing: The state of the artâ€”Part II},
  author={Gardner, Everette S},
  journal={International journal of forecasting},
  volume={22},
  number={4},
  pages={637--666},
  year={2006},
  publisher={Elsevier}
}
@article{williams1995gradient,
  title={Gradient-based learning algorithms for recurrent networks and their computational complexity},
  author={Williams, Ronald J and Zipser, David},
  journal={Backpropagation: Theory, architectures, and applications},
  volume={1},
  pages={433--486},
  year={1995},
  publisher={Lawrence Erlbaum Publ}
}
@article{schmeiser2001biased,
  title={Biased control-variate estimation},
  author={Schmeiser, Bruce W and Taaffe, Michael R and Wang, Jin},
  journal={Iie Transactions},
  volume={33},
  number={3},
  pages={219--228},
  year={2001},
  publisher={Taylor \& Francis}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  edition={1st},
  year={1998},
  publisher={MIT press Cambridge}
}
@inproceedings{seijen2014true,
  title={True online TD (lambda)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}
@inproceedings{kearns2000bias,
  title={Bias-Variance Error Bounds for Temporal Difference Updates.},
  author={Kearns, Michael J and Singh, Satinder P},
  year={2000}
}
@article{williams1995gradient,
  title={Gradient-based learning algorithms for recurrent networks and their computational complexity},
  author={Williams, Ronald J and Zipser, David},
  journal={Backpropagation: Theory, architectures, and applications},
  volume={1},
  pages={433--486},
  publisher={Lawrence Erlbaum Publ}
}

@inproceedings{van2017hybrid,
  title={Hybrid reward architecture for reinforcement learning},
  author={Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5392--5402},
  year={2017}
}
@article{neu2017unified,
  title={A unified view of entropy-regularized markov decision processes},
  author={Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
  journal={arXiv preprint arXiv:1705.07798},
  year={2017}
}
@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley  Sons}
}
@inproceedings{ferns2004metrics,
  title={Metrics for finite Markov decision processes},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={Proceedings of the 20th conference on Uncertainty in artificial intelligence},
  pages={162--169},
  year={2004},
  organization={AUAI Press}
}

@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2008},
  publisher={American Mathematical Soc.}
}
@inproceedings{pazis2011non,
  title={Non-Parametric Approximate Linear Programming for MDPs.},
  author={Pazis, Jason and Parr, Ronald},
  booktitle={AAAI},
  year={2011}
}
@article{petrik2010feature,
  title={Feature selection using regularization in approximate linear programs for Markov decision processes},
  author={Petrik, Marek and Taylor, Gavin and Parr, Ron and Zilberstein, Shlomo},
  journal={arXiv preprint arXiv:1005.1860},
  year={2010}
}
@inproceedings{liu2012regularized,
  title={Regularized off-policy TD-learning},
  author={Liu, Bo and Mahadevan, Sridhar and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={836--844},
  year={2012}
}

@inproceedings{bartlett2009regal,
  title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs},
  author={Bartlett, Peter L and Tewari, Ambuj},
  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  pages={35--42},
  year={2009},
  organization={AUAI Press}
}
@article{baxter2001infinite,
  title={Infinite-horizon policy-gradient estimation},
  author={Baxter, Jonathan and Bartlett, Peter L},
  journal={Journal of Artificial Intelligence Research},
  volume={15},
  pages={319--350},
  year={2001}
}

@phdthesis{farahmand2011regularization,
  title={Regularization in reinforcement learning},
  author={Farahmand, Amir-massoud},
  year={2011},
  school={University of Alberta},
  type     = {{PhD} thesis}
}

@inproceedings{massoud2009regularized,
  title={Regularized fitted Q-iteration for planning in continuous-space Markovian decision problems},
  author={Farahmand, Amir-massoud and Ghavamzadeh, Mohammad and Szepesv{\'a}ri, Csaba and Mannor, Shie},
  booktitle={American Control Conference},
  pages={725--730},
  year={2009},
  organization={IEEE}
}

@article{harrigan2016deep,
  title={Deep reinforcement learning with regularized convolutional neural fitted q iteration},
  author={Harrigan, Cosmo},
  year={2016}
}
@article{tsitsiklis2002average,
  title={On average versus discounted reward temporal-difference learning},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={Machine Learning},
  volume={49},
  number={2-3},
  pages={179--191},
  year={2002},
  publisher={Springer}
}
@ARTICLE {smooth_value,
    author  = " Laroche, Van Seijen",
    title   = "IN REINFORCEMENT LEARNING, ALL OBJECTIVE FUNCTIONS ARE NOT EQUAL",
    journal = "ICLR  Workshop",
    year    = "2018"
}


@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@article{kemeny1976finite,
  title={Finite markov chains, undergraduate texts in mathematics},
  author={Kemeny, John G and Snell, James Laurie},
  year={1976}
}

@book{sutton2017reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  edition={(in progress) 2nd},
  year={2017},
  publisher={MIT press Cambridge}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@incollection{singh1994learning,
  title={Learning without state-estimation in partially observable Markovian decision processes},
  author={Singh, Satinder P and Jaakkola, Tommi and Jordan, Michael I},
  booktitle={Machine Learning Proceedings 1994},
  pages={284--292},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{sutton2007role,
  title={On the role of tracking in stationary environments},
  author={Sutton, Richard S and Koop, Anna and Silver, David},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={871--878},
  year={2007},
  organization={ACM}
}
@book{farahmand2011regularization,
  title={Regularization in reinforcement learning},
  author={Farahmand, Amir-massoud},
  year={2011},
  publisher={University of Alberta Edmonoton, Canada}
}
@article{diaconis1991geometric,
  title={Geometric bounds for eigenvalues of Markov chains},
  author={Diaconis, Persi and Stroock, Daniel},
  journal={The Annals of Applied Probability},
  pages={36--61},
  year={1991},
  publisher={JSTOR}
}
@article{leike2016nonparametric,
  title={Nonparametric General Reinforcement Learning},
  author={Leike, Jan},
  journal={arXiv preprint arXiv:1611.08944},
  year={2016}
}
@book{norris1998markov,
  title={Markov chains},
  author={Norris, James R},
  number={2},
  year={1998},
  publisher={Cambridge university press}
}
@book{bremaud2013markov,
  title={Markov chains: Gibbs fields, Monte Carlo simulation, and queues},
  author={Br{\'e}maud, Pierre},
  volume={31},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}
@article{harb2017waiting,
  title={When waiting is not an option: Learning options with a deliberation cost},
  author={Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
  journal={arXiv preprint arXiv:1709.04571},
  year={2017}
}
@inproceedings{kearns2000bias,
  title={Bias-Variance Error Bounds for Temporal Difference Updates.},
  author={Kearns, Michael J and Singh, Satinder P},
  organization={Citeseer}
}
@article{sutton1984temporal,
  title={Temporal credit assignment in reinforcement learning},
  author={Sutton, Richard Stuart},
  year={1984}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}
@article{singh1996reinforcement,
  title={Reinforcement learning with replacing eligibility traces},
  author={Singh, Satinder P and Sutton, Richard S},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={123--158},
  year={1996},
  publisher={Springer}
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}
@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@article{banach1922operations,
  title={Sur les op{\'e}rations dans les ensembles abstraits et leur application aux {\'e}quations int{\'e}grales},
  year={1922},
  author={Banach, Stefan}
}
@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}
@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}
@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}
@inproceedings{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  pages={5279--5288},
  year={2017}
}
@inproceedings{seijen2014true,
  title={True online TD (lambda)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}
@article{golub1961chebyshev,
  title={Chebyshev semi-iterative methods, successive overrelaxation iterative methods, and second order Richardson iterative methods},
  author={Golub, Gene H and Varga, Richard S},
  journal={Numerische Mathematik},
  volume={3},
  number={1},
  pages={147--156},
  year={1961},
  publisher={Springer}
}
@book{varga2009matrix,
  title={Matrix iterative analysis},
  author={Varga, Richard S},
  volume={27},
  year={2009},
  publisher={Springer Science \& Business Media}
}
@inproceedings{sutton1994step,
  title={On step-size and bias in temporal-difference learning},
  author={Sutton, Richard S and Singh, Satinder P},
  organization={Citeseer}
}
@article{pbacon_del,
  author    = {Jean Harb and
               Pierre{-}Luc Bacon and
               Martin Klissarov and
               Doina Precup},
  title     = {When Waiting is not an Option : Learning Options with a Deliberation
               Cost},
  journal   = {CoRR},
  volume    = {abs/1709.04571},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.04571},
  archivePrefix = {arXiv},
  eprint    = {1709.04571},
  timestamp = {Mon, 13 Aug 2018 16:47:53 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-04571},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons}
}

@article{williams1995gradient,
  title={Gradient-based learning algorithms for recurrent networks and their computational complexity},
  author={Williams, Ronald J and Zipser, David},
  journal={Backpropagation: Theory, architectures, and applications},
  volume={1},
  pages={433--486},
  year={1995},
  publisher={Lawrence Erlbaum Publ}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}
@inproceedings{seijen2014true,
  title={True online TD (lambda)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}
@article{tallec2018can,
  title={Can recurrent neural networks warp time?},
  author={Tallec, Corentin and Ollivier, Yann},
  journal={arXiv preprint arXiv:1804.11188},
  year={2018}
}
@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}
@inproceedings{xu2017natural,
  title={Natural Value Approximators: Learning when to Trust Past Estimates},
  author={Xu, Zhongwen and Modayil, Joseph and van Hasselt, Hado P and Barreto, Andre and Silver, David and Schaul, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2120--2128},
  year={2017}
}
@inproceedings{thodoroff2018temporal,
  title={Temporal Regularization for Markov Decision Process},
  author={Thodoroff, Pierre and Durand, Audrey and Pineau, Joelle and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1782--1792},
  year={2018}
}
@article{feinberg2004continuous,
  title={Continuous time discounted jump Markov decision processes: a discrete-event approach},
  author={Feinberg, Eugene A},
  journal={Mathematics of Operations Research},
  volume={29},
  number={3},
  pages={492--524},
  year={2004},
  publisher={INFORMS}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}
@article{chung2012chernoff,
  title={Chernoff-Hoeffding bounds for Markov chains: Generalized and simplified},
  author={Chung, Kai-Min and Lam, Henry and Liu, Zhenming and Mitzenmacher, Michael},
  journal={arXiv preprint arXiv:1201.0559},
  year={2012}
}
@article{xu2018meta,
  title={Meta-Gradient Reinforcement Learning},
  author={Xu, Zhongwen and van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1805.09801},
  year={2018}
}
@article{tishby2011information,
  title={Information theory of decisions and actions},
  author={Tishby, Naftali and Polani, Daniel},
  booktitle={Perception-action cycle},
  pages={601--636},
  year={2011},
  publisher={Springer}
}
@inproceedings{white2016greedy,
  title={A greedy approach to adapting the trace parameter for temporal difference learning},
  author={White, Martha and White, Adam},
  booktitle={Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
  pages={557--565},
  year={2016},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@article{fill1991eigenvalue,
  title={Eigenvalue bounds on convergence to stationarity for nonreversible Markov chains, with an application to the exclusion process},
  author={Fill, James Allen},
  journal={The annals of applied probability},
  pages={62--87},
  year={1991},
  publisher={JSTOR}
}
@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}
@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}
@article{golub1961chebyshev,
  title={Chebyshev semi-iterative methods, successive overrelaxation iterative methods, and second order Richardson iterative methods},
  author={Golub, Gene H and Varga, Richard S},
  journal={Numerische Mathematik},
  volume={3},
  number={1},
  pages={147--156},
  year={1961},
  publisher={Springer}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}
@article{gardner1985exponential,
  title={Exponential smoothing: The state of the art},
  author={Gardner Jr, Everette S},
  journal={Journal of forecasting},
  volume={4},
  number={1},
  pages={1--28},
  year={1985},
  publisher={Wiley Online Library}
}
@article{ekern1981adaptive,
  title={Adaptive exponential smoothing revisited},
  author={Ekern, Steinar},
  journal={Journal of the Operational Research Society},
  volume={32},
  number={9},
  pages={775--782},
  year={1981},
  publisher={Taylor \& Francis}
}
@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM Journal on Control and Optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@inproceedings{jiang2015dependence,
  title={The dependence of effective planning horizon on model accuracy},
  author={Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
  booktitle={Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
  pages={1181--1189},
  year={2015},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}
@article{shah2018q,
  title={Q-learning with Nearest Neighbors},
  author={Shah, Devavrat and Xie, Qiaomin},
  journal={arXiv preprint arXiv:1802.03900},
  year={2018}
}
@inproceedings{sutton2007role,
  title={On the role of tracking in stationary environments},
  author={Sutton, Richard S and Koop, Anna and Silver, David},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={871--878},
  year={2007},
  organization={ACM}
}
@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}
@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}
@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}
@misc{pytorchrl,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr}},
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@article{suttonreinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  publisher={Citeseer}
}
@inproceedings{franccois2016deep,
  title={Deep reinforcement learning solutions for energy microgrids management},
  author={Fran{\c{c}}ois-Lavet, Vincent and Taralla, David and Ernst, Damien and Fonteneau, Rapha{\"e}l},
  booktitle={European Workshop on Reinforcement Learning (EWRL 2016)},
  year={2016}
}
@inproceedings{grinberg2014optimizing,
  title={Optimizing energy production using policy search and predictive state representations},
  author={Grinberg, Yuri and Precup, Doina and Gendreau, Michel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2969--2977},
  year={2014}
}
@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}
@article{abbeel2010autonomous,
  title={Autonomous helicopter aerobatics through apprenticeship learning},
  author={Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
  journal={The International Journal of Robotics Research},
  volume={29},
  number={13},
  pages={1608--1639},
  year={2010},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS-W},
  year={2017},
}
@inproceedings{harb2018waiting,
  title={When waiting is not an option: Learning options with a deliberation cost},
  author={Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{TVT,
Author = {Chia-Chun Hung and Timothy Lillicrap and Josh Abramson and Yan Wu and Mehdi Mirza and Federico Carnevale and Arun Ahuja and Greg Wayne},
Title = {Optimizing Agent Behavior over Long Time Scales by Transporting Value},
Year = {2018},
Eprint = {arXiv:1810.06721},
}
@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@article{dayan1992convergence,
  title={The convergence of TD ($\lambda$) for general $\lambda$},
  author={Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={341--362},
  year={1992},
  publisher={Springer}
}
@article{pbacon_del,
  author    = {Jean Harb and
               Pierre{-}Luc Bacon and
               Martin Klissarov and
               Doina Precup},
  title     = {When Waiting is not an Option : Learning Options with a Deliberation
               Cost},
  journal   = {CoRR},
  volume    = {abs/1709.04571},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.04571},
  archivePrefix = {arXiv},
  eprint    = {1709.04571},
  timestamp = {Mon, 13 Aug 2018 16:47:53 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-04571},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons}
}

@article{williams1995gradient,
  title={Gradient-based learning algorithms for recurrent networks and their computational complexity},
  author={Williams, Ronald J and Zipser, David},
  journal={Backpropagation: Theory, architectures, and applications},
  volume={1},
  pages={433--486},
  year={1995},
  publisher={Lawrence Erlbaum Publ}
}
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016}
}
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  year={1998},
  publisher={MIT press Cambridge}
}
@inproceedings{seijen2014true,
  title={True online TD (lambda)},
  author={Seijen, Harm and Sutton, Rich},
  booktitle={International Conference on Machine Learning},
  pages={692--700},
  year={2014}
}
@article{tallec2018can,
  title={Can recurrent neural networks warp time?},
  author={Tallec, Corentin and Ollivier, Yann},
  journal={arXiv preprint arXiv:1804.11188},
  year={2018}
}
@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}
@inproceedings{xu2017natural,
  title={Natural Value Approximators: Learning when to Trust Past Estimates},
  author={Xu, Zhongwen and Modayil, Joseph and van Hasselt, Hado P and Barreto, Andre and Silver, David and Schaul, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2120--2128},
  year={2017}
}
@inproceedings{thodoroff2018temporal,
  title={Temporal Regularization for Markov Decision Process},
  author={Thodoroff, Pierre and Durand, Audrey and Pineau, Joelle and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1782--1792},
  year={2018}
}
@article{feinberg2004continuous,
  title={Continuous time discounted jump Markov decision processes: a discrete-event approach},
  author={Feinberg, Eugene A},
  journal={Mathematics of Operations Research},
  volume={29},
  number={3},
  pages={492--524},
  year={2004},
  publisher={INFORMS}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}
@article{chung2012chernoff,
  title={Chernoff-Hoeffding bounds for Markov chains: Generalized and simplified},
  author={Chung, Kai-Min and Lam, Henry and Liu, Zhenming and Mitzenmacher, Michael},
  journal={arXiv preprint arXiv:1201.0559},
  year={2012}
}
@article{xu2018meta,
  title={Meta-Gradient Reinforcement Learning},
  author={Xu, Zhongwen and van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1805.09801},
  year={2018}
}
@article{tishby2011information,
  title={Information theory of decisions and actions},
  author={Tishby, Naftali and Polani, Daniel},
  booktitle={Perception-action cycle},
  pages={601--636},
  year={2011},
  publisher={Springer}
}
@inproceedings{white2016greedy,
  title={A greedy approach to adapting the trace parameter for temporal difference learning},
  author={White, Martha and White, Adam},
  booktitle={Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
  pages={557--565},
  year={2016},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@article{fill1991eigenvalue,
  title={Eigenvalue bounds on convergence to stationarity for nonreversible Markov chains, with an application to the exclusion process},
  author={Fill, James Allen},
  journal={The annals of applied probability},
  pages={62--87},
  year={1991},
  publisher={JSTOR}
}
@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}
@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}
@article{golub1961chebyshev,
  title={Chebyshev semi-iterative methods, successive overrelaxation iterative methods, and second order Richardson iterative methods},
  author={Golub, Gene H and Varga, Richard S},
  journal={Numerische Mathematik},
  volume={3},
  number={1},
  pages={147--156},
  year={1961},
  publisher={Springer}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}
@article{gardner1985exponential,
  title={Exponential smoothing: The state of the art},
  author={Gardner Jr, Everette S},
  journal={Journal of forecasting},
  volume={4},
  number={1},
  pages={1--28},
  year={1985},
  publisher={Wiley Online Library}
}
@article{ekern1981adaptive,
  title={Adaptive exponential smoothing revisited},
  author={Ekern, Steinar},
  journal={Journal of the Operational Research Society},
  volume={32},
  number={9},
  pages={775--782},
  year={1981},
  publisher={Taylor \& Francis}
}
@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM Journal on Control and Optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@inproceedings{jiang2015dependence,
  title={The dependence of effective planning horizon on model accuracy},
  author={Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
  booktitle={Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
  pages={1181--1189},
  year={2015},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}
@article{shah2018q,
  title={Q-learning with Nearest Neighbors},
  author={Shah, Devavrat and Xie, Qiaomin},
  journal={arXiv preprint arXiv:1802.03900},
  year={2018}
}
@inproceedings{sutton2007role,
  title={On the role of tracking in stationary environments},
  author={Sutton, Richard S and Koop, Anna and Silver, David},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={871--878},
  year={2007},
  organization={ACM}
}
@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}
@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}
@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}
@misc{pytorchrl,
  author = {Kostrikov, Ilya},
  title = {PyTorch Implementations of Reinforcement Learning Algorithms},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr}},
}
@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@article{suttonreinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  publisher={Citeseer}
}
@inproceedings{franccois2016deep,
  title={Deep reinforcement learning solutions for energy microgrids management},
  author={Fran{\c{c}}ois-Lavet, Vincent and Taralla, David and Ernst, Damien and Fonteneau, Rapha{\"e}l},
  booktitle={European Workshop on Reinforcement Learning (EWRL 2016)},
  year={2016}
}
@inproceedings{grinberg2014optimizing,
  title={Optimizing energy production using policy search and predictive state representations},
  author={Grinberg, Yuri and Precup, Doina and Gendreau, Michel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2969--2977},
  year={2014}
}
@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}
@article{abbeel2010autonomous,
  title={Autonomous helicopter aerobatics through apprenticeship learning},
  author={Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
  journal={The International Journal of Robotics Research},
  volume={29},
  number={13},
  pages={1608--1639},
  year={2010},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@inproceedings{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS-W},
  year={2017},
}
@inproceedings{harb2018waiting,
  title={When waiting is not an option: Learning options with a deliberation cost},
  author={Harb, Jean and Bacon, Pierre-Luc and Klissarov, Martin and Precup, Doina},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{TVT,
Author = {Chia-Chun Hung and Timothy Lillicrap and Josh Abramson and Yan Wu and Mehdi Mirza and Federico Carnevale and Arun Ahuja and Greg Wayne},
Title = {Optimizing Agent Behavior over Long Time Scales by Transporting Value},
Year = {2018},
Eprint = {arXiv:1810.06721},
}
@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@article{dayan1992convergence,
  title={The convergence of TD ($\lambda$) for general $\lambda$},
  author={Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={341--362},
  year={1992},
  publisher={Springer}
}

@article{sutton1985temporal,
  title={Temporal Credit Assignment in Reinforcement Learning.},
  author={Sutton, Richard S},
  year={1985}
}
@inproceedings{jaakkola1995reinforcement,
  title={Reinforcement learning algorithm for partially observable Markov decision problems},
  author={Jaakkola, Tommi and Singh, Satinder P and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={345--352},
  year={1995}
}

@inproceedings{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in neural information processing systems},
  pages={5279--5288},
  year={2017}
}
@article{zhang2018dissection,
  title={A dissection of overfitting and generalization in continuous reinforcement learning},
  author={Zhang, Amy and Ballas, Nicolas and Pineau, Joelle},
  journal={arXiv preprint arXiv:1806.07937},
  year={2018}
}

@article{chung2018two,
  title={Two-Timescale Networks for Nonlinear Value Function Approximation},
  author={Chung, Wesley and Nath, Somjit and Joseph, Ajin and White, Martha},
  year={2018}
}

@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}
@article{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  journal={arXiv preprint arXiv:1512.08562},
  year={2015}
}
@book{pendrith1994reinforcement,
  title={On reinforcement learning of control actions in noisy and non-Markovian domains},
  author={Pendrith, Mark D},
  publisher={Citeseer}
}
@article{greensmith2004variance,
  title={Variance reduction techniques for gradient estimates in reinforcement learning},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Nov},
  pages={1471--1530},
  year={2004}
}
@article{glascher2010states,
  title={States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning},
  author={Gl{\"a}scher, Jan and Daw, Nathaniel and Dayan, Peter and O'Doherty, John P},
  journal={Neuron},
  volume={66},
  number={4},
  pages={585--595},
  year={2010},
  publisher={Elsevier}
}
@phdthesis{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath and others},
  year={2003}
}
@inproceedings{van2016learning,
  title={Learning values across many orders of magnitude},
  author={van Hasselt, Hado P and Guez, Arthur and Hessel, Matteo and Mnih, Volodymyr and Silver, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4287--4295},
  year={2016}
}
@article{romoff2018reward,
  title={Reward estimation for variance reduction in deep reinforcement learning},
  author={Romoff, Joshua and Henderson, Peter and Pich{\'e}, Alexandre and Francois-Lavet, Vincent and Pineau, Joelle},
  journal={arXiv preprint arXiv:1805.03359},
  year={2018}
}
